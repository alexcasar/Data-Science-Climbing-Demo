{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference, forecast and optimization\n",
    "\n",
    "Ok, the final step in this exercise will be to use the data and variables to start infering, forecasting and optimizing the result of a target variable, instead of just trying to describe what already is happening.\n",
    "\n",
    "To do this, we can create a model based on all the data available (common approach, but not the best one if you already know that different subjects behave differently) or we can create models for a specific subset of the entire population.\n",
    "\n",
    "This notebook will showcase both.\n",
    "\n",
    "*One thing to note is that I do not expect the models to have a very good performance, it is mainly illustrative, because we are dealing with a very small database. Having only ~150 climbers, to cover the entire range of grades from 5.8 to 5.15d, gives very few examples of each grade for the algorithms to properly learn patterns. But replicating this same strategy with a database that is tens, hundreds or thousands of times bigger will yield much better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.neighbors import NearestNeighbors, KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData = pd.read_csv(\"filteredData.csv\").replace(np.nan,0)\n",
    "normData = pd.read_csv(\"normData.csv\").replace(np.nan,0)\n",
    "\n",
    "mixedData = normData.copy()\n",
    "mixedData.iloc[:,-17:] = fullData.iloc[:,-17:]\n",
    "\n",
    "features = pd.read_csv(\"features.csv\")\n",
    "testImportant = mixedData.loc[:,features.loc[features.loc[:,\"IMPORTANT\"]==1,\"FEATURE\"]]\n",
    "testImportant[\"S_AVG\"]=fullData[\"S_AVG\"]\n",
    "testBest = mixedData.loc[:,features.loc[features.loc[:,\"BEST\"]==1,\"FEATURE\"]]\n",
    "testBest[\"S_AVG\"]=fullData[\"S_AVG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAC_MOON</th>\n",
       "      <th>C_NA</th>\n",
       "      <th>WHY_HEALTH</th>\n",
       "      <th>DIET_OTHER</th>\n",
       "      <th>TRAIN_BOOK</th>\n",
       "      <th>PROJECTING</th>\n",
       "      <th>IN_NA</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>TRAVEL</th>\n",
       "      <th>OUTDOOR</th>\n",
       "      <th>...</th>\n",
       "      <th>TRAINLENGTH</th>\n",
       "      <th>FOCUS_FLEX</th>\n",
       "      <th>C_CSA</th>\n",
       "      <th>INDOORDAYS</th>\n",
       "      <th>FAC_AUTO</th>\n",
       "      <th>FAC_BOARDS</th>\n",
       "      <th>OCC_FULL</th>\n",
       "      <th>INDOOR</th>\n",
       "      <th>APEINDEX</th>\n",
       "      <th>S_AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.270968</td>\n",
       "      <td>0.574194</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.480645</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.347789</td>\n",
       "      <td>0.245806</td>\n",
       "      <td>0.264516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352419</td>\n",
       "      <td>0.380645</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.283871</td>\n",
       "      <td>0.238710</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.465077</td>\n",
       "      <td>5.359677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.480015</td>\n",
       "      <td>0.445900</td>\n",
       "      <td>0.496067</td>\n",
       "      <td>0.257603</td>\n",
       "      <td>0.193527</td>\n",
       "      <td>0.385971</td>\n",
       "      <td>0.221961</td>\n",
       "      <td>0.151042</td>\n",
       "      <td>0.325135</td>\n",
       "      <td>0.442505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278589</td>\n",
       "      <td>0.487119</td>\n",
       "      <td>0.234623</td>\n",
       "      <td>0.169959</td>\n",
       "      <td>0.427677</td>\n",
       "      <td>0.475896</td>\n",
       "      <td>0.499266</td>\n",
       "      <td>0.455383</td>\n",
       "      <td>0.129336</td>\n",
       "      <td>3.905341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>8.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FAC_MOON        C_NA  WHY_HEALTH  DIET_OTHER  TRAIN_BOOK  PROJECTING  \\\n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  155.000000   \n",
       "mean     0.354839    0.270968    0.574194    0.070968    0.038710    0.480645   \n",
       "std      0.480015    0.445900    0.496067    0.257603    0.193527    0.385971   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    1.000000    0.000000    0.000000    0.500000   \n",
       "75%      1.000000    1.000000    1.000000    0.000000    0.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "            IN_NA      WEIGHT      TRAVEL     OUTDOOR     ...      \\\n",
       "count  155.000000  155.000000  155.000000  155.000000     ...       \n",
       "mean     0.051613    0.347789    0.245806    0.264516     ...       \n",
       "std      0.221961    0.151042    0.325135    0.442505     ...       \n",
       "min      0.000000    0.000000    0.000000    0.000000     ...       \n",
       "25%      0.000000    0.235294    0.050000    0.000000     ...       \n",
       "50%      0.000000    0.338235    0.100000    0.000000     ...       \n",
       "75%      0.000000    0.441176    0.300000    1.000000     ...       \n",
       "max      1.000000    1.000000    1.000000    1.000000     ...       \n",
       "\n",
       "       TRAINLENGTH  FOCUS_FLEX       C_CSA  INDOORDAYS    FAC_AUTO  \\\n",
       "count   155.000000  155.000000  155.000000  155.000000  155.000000   \n",
       "mean      0.352419    0.380645    0.058065    0.283871    0.238710   \n",
       "std       0.278589    0.487119    0.234623    0.169959    0.427677   \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%       0.125000    0.000000    0.000000    0.142857    0.000000   \n",
       "50%       0.375000    0.000000    0.000000    0.285714    0.000000   \n",
       "75%       0.625000    1.000000    0.000000    0.428571    0.000000   \n",
       "max       1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "       FAC_BOARDS    OCC_FULL      INDOOR    APEINDEX       S_AVG  \n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  \n",
       "mean     0.658065    0.451613    0.290323    0.465077    5.359677  \n",
       "std      0.475896    0.499266    0.455383    0.129336    3.905341  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.434783    2.000000  \n",
       "50%      1.000000    0.000000    0.000000    0.434783    5.500000  \n",
       "75%      1.000000    1.000000    1.000000    0.434783    8.250000  \n",
       "max      1.000000    1.000000    1.000000    1.000000   15.250000  \n",
       "\n",
       "[8 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testImportant.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAC_MOON</th>\n",
       "      <th>WHY_HEALTH</th>\n",
       "      <th>PROJECTING</th>\n",
       "      <th>START_AGE</th>\n",
       "      <th>WHY_COMP</th>\n",
       "      <th>ROUTEQTY</th>\n",
       "      <th>TRAIN_CLIMB</th>\n",
       "      <th>FOCUS_POW</th>\n",
       "      <th>SHOEFIT</th>\n",
       "      <th>FOCUS_FOOT</th>\n",
       "      <th>...</th>\n",
       "      <th>CLIMBDAYS</th>\n",
       "      <th>FOCUS_EXPLO</th>\n",
       "      <th>SPORT</th>\n",
       "      <th>VACATIONS</th>\n",
       "      <th>YRS_CLIMBING</th>\n",
       "      <th>BOULDER</th>\n",
       "      <th>INDOORDAYS</th>\n",
       "      <th>INDOOR</th>\n",
       "      <th>APEINDEX</th>\n",
       "      <th>S_AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.574194</td>\n",
       "      <td>0.480645</td>\n",
       "      <td>0.285626</td>\n",
       "      <td>0.083871</td>\n",
       "      <td>0.203871</td>\n",
       "      <td>0.219355</td>\n",
       "      <td>0.541935</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456989</td>\n",
       "      <td>0.309677</td>\n",
       "      <td>0.503226</td>\n",
       "      <td>0.453763</td>\n",
       "      <td>0.159238</td>\n",
       "      <td>0.212903</td>\n",
       "      <td>0.283871</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.465077</td>\n",
       "      <td>5.359677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.480015</td>\n",
       "      <td>0.496067</td>\n",
       "      <td>0.385971</td>\n",
       "      <td>0.154549</td>\n",
       "      <td>0.278093</td>\n",
       "      <td>0.147218</td>\n",
       "      <td>0.415151</td>\n",
       "      <td>0.499853</td>\n",
       "      <td>0.246088</td>\n",
       "      <td>0.501360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196321</td>\n",
       "      <td>0.463859</td>\n",
       "      <td>0.501610</td>\n",
       "      <td>0.273621</td>\n",
       "      <td>0.180005</td>\n",
       "      <td>0.410687</td>\n",
       "      <td>0.169959</td>\n",
       "      <td>0.455383</td>\n",
       "      <td>0.129336</td>\n",
       "      <td>3.905341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.331395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>8.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FAC_MOON  WHY_HEALTH  PROJECTING   START_AGE    WHY_COMP    ROUTEQTY  \\\n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  155.000000   \n",
       "mean     0.354839    0.574194    0.480645    0.285626    0.083871    0.203871   \n",
       "std      0.480015    0.496067    0.385971    0.154549    0.278093    0.147218   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.209302    0.000000    0.133333   \n",
       "50%      0.000000    1.000000    0.500000    0.255814    0.000000    0.166667   \n",
       "75%      1.000000    1.000000    1.000000    0.331395    0.000000    0.233333   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "       TRAIN_CLIMB   FOCUS_POW     SHOEFIT  FOCUS_FOOT     ...      \\\n",
       "count   155.000000  155.000000  155.000000  155.000000     ...       \n",
       "mean      0.219355    0.541935    0.569892    0.516129     ...       \n",
       "std       0.415151    0.499853    0.246088    0.501360     ...       \n",
       "min       0.000000    0.000000    0.000000    0.000000     ...       \n",
       "25%       0.000000    0.000000    0.333333    0.000000     ...       \n",
       "50%       0.000000    1.000000    0.666667    1.000000     ...       \n",
       "75%       0.000000    1.000000    0.666667    1.000000     ...       \n",
       "max       1.000000    1.000000    1.000000    1.000000     ...       \n",
       "\n",
       "        CLIMBDAYS  FOCUS_EXPLO       SPORT   VACATIONS  YRS_CLIMBING  \\\n",
       "count  155.000000   155.000000  155.000000  155.000000    155.000000   \n",
       "mean     0.456989     0.309677    0.503226    0.453763      0.159238   \n",
       "std      0.196321     0.463859    0.501610    0.273621      0.180005   \n",
       "min      0.000000     0.000000    0.000000    0.000000      0.000000   \n",
       "25%      0.333333     0.000000    0.000000    0.333333      0.049180   \n",
       "50%      0.500000     0.000000    1.000000    0.333333      0.114754   \n",
       "75%      0.500000     1.000000    1.000000    0.666667      0.180328   \n",
       "max      1.000000     1.000000    1.000000    1.000000      1.000000   \n",
       "\n",
       "          BOULDER  INDOORDAYS      INDOOR    APEINDEX       S_AVG  \n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  \n",
       "mean     0.212903    0.283871    0.290323    0.465077    5.359677  \n",
       "std      0.410687    0.169959    0.455383    0.129336    3.905341  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.142857    0.000000    0.434783    2.000000  \n",
       "50%      0.000000    0.285714    0.000000    0.434783    5.500000  \n",
       "75%      0.000000    0.428571    1.000000    0.434783    8.250000  \n",
       "max      1.000000    1.000000    1.000000    1.000000   15.250000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testBest.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try the general approach with both the \"best\" and the \"important\" datasets to see which performs best, then we can go into the subset modeling only with the better performing one.\n",
    "\n",
    "Lets define the trainModel function since it will be used several times, then lets use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model,db,indexes,tests,goal):\n",
    "    X = db.copy().drop(goal,axis=1)\n",
    "    X = X.loc[indexes,:]\n",
    "    y = db.copy()[goal]\n",
    "    y = y[indexes]\n",
    "\n",
    "    high_score=0\n",
    "    score_list =[]\n",
    "    topTRF = 0\n",
    "    topFeatsRF = 0\n",
    "    topFeatsPosRF = 0\n",
    "    topFeatsRankRF = 0\n",
    "    featValsRF = 0\n",
    "    topModel = RandomForestRegressor(n_estimators=100)\n",
    "    topX_train = 0\n",
    "    topX_test = 0\n",
    "    topy_train = 0\n",
    "    topy_test = 0\n",
    "    for t in tests: \n",
    "        print(t)\n",
    "        #Variable to store the optimum features\n",
    "        for n in range(1,len(X.columns)):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = t, random_state = 0)\n",
    "            model = RandomForestRegressor(n_estimators=100)\n",
    "            rfe = RFECV(model,n,cv=10)\n",
    "            X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "            X_test_rfe = rfe.transform(X_test)\n",
    "            model.fit(X_train_rfe,y_train)\n",
    "            score = model.score(X_test_rfe,y_test)\n",
    "            score_list.append(score)\n",
    "            if(score>high_score and rfe.n_features_>9 and rfe.n_features_<40):\n",
    "                topTRF = t\n",
    "                high_score = score\n",
    "                nof = rfe.n_features_\n",
    "                topFeatsPosRF = rfe.support_\n",
    "                topFeatsRF = X.columns[topFeatsPosRF]\n",
    "                topFeatsRankRF = rfe.ranking_\n",
    "                featValsRF = model.feature_importances_\n",
    "                topModel.fit(X_train_rfe,y_train)\n",
    "                topX_train = X_train\n",
    "                topX_test = X_test\n",
    "                topy_train = y_train\n",
    "                topy_test = y_test\n",
    "                print(\"Score with %d features: %f\" % (nof, high_score))\n",
    "                \n",
    "    return topModel, topFeatsRF, topFeatsPosRF, topX_train, topX_test, topy_train, topy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "Score with 23 features: 0.406980\n",
      "Score with 24 features: 0.408235\n",
      "Score with 24 features: 0.416757\n",
      "Score with 24 features: 0.438325\n",
      "Score with 24 features: 0.456440\n",
      "0.3\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "modelB = RandomForestRegressor(n_estimators=100)\n",
    "tests = [.25, .3, .35]\n",
    "\n",
    "modelB,featsB,featspB,x_trB,x_tsB,y_trB,y_tsB = trainModel(modelB,testBest,testBest.index,tests,\"S_AVG\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\tPred\tReal\tError\n",
      "0\t5.6975\t6.0\t0.3025000000000002\n",
      "1\t2.3675\t0.0\t-2.3675\n",
      "2\t2.3875\t2.5\t0.11249999999999982\n",
      "3\t4.3125\t3.5\t-0.8125\n",
      "4\t5.125\t11.0\t5.875\n",
      "5\t3.2275\t4.75\t1.5225\n",
      "6\t5.78\t0.0\t-5.78\n",
      "7\t4.6025\t0.0\t-4.6025\n",
      "8\t5.33\t4.75\t-0.5800000000000001\n",
      "9\t4.3775\t5.0\t0.6224999999999996\n",
      "10\t8.595\t8.0\t-0.5950000000000006\n",
      "11\t5.6175\t9.75\t4.1325\n",
      "12\t0.8925\t0.0\t-0.8925\n",
      "13\t3.675\t0.0\t-3.675\n",
      "14\t4.1225\t5.0\t0.8775000000000004\n",
      "15\t5.6\t5.5\t-0.09999999999999964\n",
      "16\t7.0275\t12.5\t5.4725\n",
      "17\t4.725\t0.0\t-4.725\n",
      "18\t5.4075\t5.0\t-0.40749999999999975\n",
      "19\t3.8575\t7.75\t3.8925\n",
      "20\t6.0325\t4.75\t-1.2824999999999998\n",
      "21\t6.4875\t6.25\t-0.23749999999999982\n",
      "22\t3.7575\t1.5\t-2.2575\n",
      "23\t2.5475\t2.0\t-0.5474999999999999\n",
      "24\t9.8225\t15.25\t5.4275\n",
      "25\t2.8425\t0.0\t-2.8425\n",
      "26\t4.7725\t6.75\t1.9775\n",
      "27\t7.825\t12.25\t4.425\n",
      "28\t7.3775\t5.25\t-2.1275000000000004\n",
      "29\t5.335\t6.25\t0.915\n",
      "30\t6.2\t14.0\t7.8\n",
      "31\t3.53\t6.75\t3.22\n",
      "32\t4.375\t0.0\t-4.375\n",
      "33\t3.32\t0.0\t-3.32\n",
      "34\t4.8275\t3.25\t-1.5774999999999997\n",
      "35\t5.7825\t10.25\t4.4675\n",
      "36\t2.87\t5.5\t2.63\n",
      "37\t4.4975\t6.0\t1.5025000000000004\n",
      "38\t5.1025\t3.0\t-2.1025\n"
     ]
    }
   ],
   "source": [
    "predicts = modelB.predict(x_tsB[featsB])\n",
    "compare = y_tsB.copy().reset_index(drop=True)\n",
    "print(\"ID\\tPred\\tReal\\tError\")\n",
    "for i,p in enumerate(predicts):\n",
    "    print(str(i)+\"\\t\"+str(p)+\"\\t\"+str(compare[i])+\"\\t\"+str(compare[i]-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "Score with 36 features: 0.334205\n",
      "0.3\n",
      "0.35\n"
     ]
    }
   ],
   "source": [
    "modelI = RandomForestRegressor(n_estimators=100)\n",
    "tests = [.25, .3, .35]\n",
    "\n",
    "modelI,featsI,featspI,x_trI,x_tsI,y_trI,y_tsI = trainModel(modelB,testImportant,testImportant.index,tests,\"S_AVG\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\tPred\tReal\tError\n",
      "0\t4.69\t6.0\t1.3099999999999996\n",
      "1\t2.8075\t0.0\t-2.8075\n",
      "2\t3.0025\t2.5\t-0.5025\n",
      "3\t3.94\t3.5\t-0.43999999999999995\n",
      "4\t4.345\t11.0\t6.655\n",
      "5\t3.8475\t4.75\t0.9024999999999999\n",
      "6\t5.8525\t0.0\t-5.8525\n",
      "7\t4.0325\t0.0\t-4.0325\n",
      "8\t5.2975\t4.75\t-0.5475000000000003\n",
      "9\t4.585\t5.0\t0.41500000000000004\n",
      "10\t7.72\t8.0\t0.28000000000000025\n",
      "11\t5.3425\t9.75\t4.4075\n",
      "12\t1.6175\t0.0\t-1.6175\n",
      "13\t4.56\t0.0\t-4.56\n",
      "14\t4.0875\t5.0\t0.9124999999999996\n",
      "15\t5.6825\t5.5\t-0.1825000000000001\n",
      "16\t6.5875\t12.5\t5.9125\n",
      "17\t3.7975\t0.0\t-3.7975\n",
      "18\t5.6675\t5.0\t-0.6675000000000004\n",
      "19\t5.16\t7.75\t2.59\n",
      "20\t5.9175\t4.75\t-1.1675000000000004\n",
      "21\t6.2425\t6.25\t0.007500000000000284\n",
      "22\t2.8175\t1.5\t-1.3175\n",
      "23\t3.12\t2.0\t-1.12\n",
      "24\t7.9325\t15.25\t7.3175\n",
      "25\t3.0075\t0.0\t-3.0075\n",
      "26\t3.9975\t6.75\t2.7525\n",
      "27\t6.73\t12.25\t5.52\n",
      "28\t7.2975\t5.25\t-2.0475000000000003\n",
      "29\t4.26\t6.25\t1.9900000000000002\n",
      "30\t5.32\t14.0\t8.68\n",
      "31\t3.7275\t6.75\t3.0225\n",
      "32\t4.6375\t0.0\t-4.6375\n",
      "33\t3.4275\t0.0\t-3.4275\n",
      "34\t5.5725\t3.25\t-2.3225\n",
      "35\t6.1225\t10.25\t4.1275\n",
      "36\t3.2675\t5.5\t2.2325\n",
      "37\t4.065\t6.0\t1.9349999999999996\n",
      "38\t4.02\t3.0\t-1.0199999999999996\n"
     ]
    }
   ],
   "source": [
    "predicts2 = modelI.predict(x_tsI[featsI])\n",
    "compare2 = y_tsI.copy().reset_index(drop=True)\n",
    "print(\"ID\\tPred\\tReal\\tError\")\n",
    "for i,p in enumerate(predicts2):\n",
    "    print(str(i)+\"\\t\"+str(p)+\"\\t\"+str(compare2[i])+\"\\t\"+str(compare2[i]-p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples above, the models use something between 65% and 75% of the data in order to train the model, and something between 25% to 35% of the data to evaluate how it performs. As specified at the beggining, having so little data, great performance was not expected. Right now using the \"best\" features we got models that can predict a climber's performance with an average error of around +-3 grades (that is, predicting between 5.8 and 11a for 5.10b climber), and errors as large as +-7 grades max, which while not great at all, it is actually better than I was hoping for in this example having only 150 climbers to learn from.\n",
    "\n",
    "As foreshadowed (even if it is initially counter-intuitive) the model using only the best features performs better than using all the important features. One could initially find it weird that using less information (around 25 vs 60 variables) would yield better results, but many times data is noisy with misleading variables that can distract from the patterns-carrying variables.\n",
    "\n",
    "Instead of showcasing how to use these models to show how a specific climber should/could be performing, or to show how to propose strategies or plans of action to achieve golas one might have, I will first show how one could prefer to group first and perform modeling on smaller groups.\n",
    "\n",
    "## Clustering and cluster analysis\n",
    "\n",
    "The predictive model we already created uses information gathered from all the climbers in order to predict how a climber would perform given his profile, his training habits, his mentality of climbing, etc. However, the model as we have it right now does not discriminate, so it will use information from a 1.95 m, 80 kg 48 year old male climber as an example of what is expected from a 1.55 m, 42 kg, 19 year old girl, and that miiiiight not be the best approach.\n",
    "\n",
    "Data Scientists usually deal with this problem by performing clustering or grouping. There are many different approaches to do this. When certain domain knowledge is possessed one could divide them manually (for example divide male and female, or divide 5.10, 5.11, 5.12, 5.13, 5.14, or divide 40-50kg, 50-60kg, etc.), when there is no clear way of how the data should be divided, one could rely on machine learning algorithms that perform automatic clustering. In case you want to learn one, the most easy to learn and implement would probably be K-means. In K-means you tell the algorithm how many groups you want, and it will find the best way it could be divided into that many groups.\n",
    "\n",
    "I will do a combination of these approaches. Since the data size is very small, and I possess some domain knowledge, I could find registry-specific-clustering. That is, instead of finding general groups of datapoints that are similar to each other, finding the datapoints that are the most similar to a particular datapoint. As an analogy to this climbing example, instead of dividing the data into groups and then finding the group that would include John, I will create a group with the climbers that are specifically the most similar to John. In data science we call this K-NN (the K - nearest neighbors) and there are algorithms in python that let us do it easily.\n",
    "\n",
    "\"Nearest\" is defined based on difference between their variables, so we first need to define the variable-subset profile we would like the algorithm to compare, instead of letting it find the nearest neighbors using all the variables.\n",
    "\n",
    "Simply for example case, I will propose the following variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>YRS_CLIMBING</th>\n",
       "      <th>HEIGHT</th>\n",
       "      <th>APEINDEX</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>BMI</th>\n",
       "      <th>B_AVG</th>\n",
       "      <th>S_AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.293923</td>\n",
       "      <td>0.159238</td>\n",
       "      <td>0.374625</td>\n",
       "      <td>0.465077</td>\n",
       "      <td>0.347789</td>\n",
       "      <td>0.466305</td>\n",
       "      <td>0.373756</td>\n",
       "      <td>0.351454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.192319</td>\n",
       "      <td>0.180005</td>\n",
       "      <td>0.167852</td>\n",
       "      <td>0.129336</td>\n",
       "      <td>0.151042</td>\n",
       "      <td>0.191770</td>\n",
       "      <td>0.189987</td>\n",
       "      <td>0.256088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.338828</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.131148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.446305</td>\n",
       "      <td>0.355932</td>\n",
       "      <td>0.360656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.360465</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.578105</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>0.540984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AGE  YRS_CLIMBING      HEIGHT    APEINDEX      WEIGHT  \\\n",
       "count  155.000000    155.000000  155.000000  155.000000  155.000000   \n",
       "mean     0.293923      0.159238    0.374625    0.465077    0.347789   \n",
       "std      0.192319      0.180005    0.167852    0.129336    0.151042   \n",
       "min      0.000000      0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.162791      0.049180    0.250000    0.434783    0.235294   \n",
       "50%      0.232558      0.114754    0.344828    0.434783    0.338235   \n",
       "75%      0.360465      0.180328    0.500000    0.434783    0.441176   \n",
       "max      1.000000      1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "              BMI       B_AVG       S_AVG  \n",
       "count  155.000000  155.000000  155.000000  \n",
       "mean     0.466305    0.373756    0.351454  \n",
       "std      0.191770    0.189987    0.256088  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.338828    0.254237    0.131148  \n",
       "50%      0.446305    0.355932    0.360656  \n",
       "75%      0.578105    0.483051    0.540984  \n",
       "max      1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnProfileVars = [\"AGE\",\"YRS_CLIMBING\",\"HEIGHT\",\"APEINDEX\",\"WEIGHT\",\"BMI\",\"B_AVG\",\"S_AVG\"]\n",
    "knnData = normData[knnProfileVars]\n",
    "knnData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason I propose this variables is because it contains their current level, and descriptive variables that they cannot change, they simply describe their current phisique and experience. In order to create groups of climbers with similar phisiques, experience and current performance, regardless of the way they train, how often they climb, how they approach improvement, what they eat, etc. because those are the variables that the climber can actually change in order to produce a change in their performance.\n",
    "\n",
    "Now lets use a KDTree (the algorithm inside the KNN algorithm) to find the nearest neighbors of a random climber, lets say the 10th climber in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After finding the 51 nearest neighbors we see this behavior in the data distribution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_CLIMBER</th>\n",
       "      <th>AVERAGE_CLIMBER</th>\n",
       "      <th>KNN_CLOSEST_AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.293923</td>\n",
       "      <td>0.208390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YRS_CLIMBING</th>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.159238</td>\n",
       "      <td>0.083253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEIGHT</th>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.374625</td>\n",
       "      <td>0.457701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APEINDEX</th>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.465077</td>\n",
       "      <td>0.455243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEIGHT</th>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.347789</td>\n",
       "      <td>0.394319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.475728</td>\n",
       "      <td>0.466305</td>\n",
       "      <td>0.461128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_AVG</th>\n",
       "      <td>0.406780</td>\n",
       "      <td>0.373756</td>\n",
       "      <td>0.347956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_AVG</th>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.351454</td>\n",
       "      <td>0.238830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SUBJECT_CLIMBER  AVERAGE_CLIMBER  KNN_CLOSEST_AVG\n",
       "AGE                  0.186047         0.293923         0.208390\n",
       "YRS_CLIMBING         0.081967         0.159238         0.083253\n",
       "HEIGHT               0.517241         0.374625         0.457701\n",
       "APEINDEX             0.434783         0.465077         0.455243\n",
       "WEIGHT               0.441176         0.347789         0.394319\n",
       "BMI                  0.475728         0.466305         0.461128\n",
       "B_AVG                0.406780         0.373756         0.347956\n",
       "S_AVG                0.229508         0.351454         0.238830"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "climberID = 10\n",
    "randomClimber = knnData.loc[climberID,:]\n",
    "tree = KDTree(knnData)     \n",
    "dist, ids = tree.query([randomClimber], k=int(len(knnData.index)/3))\n",
    "\n",
    "closestClimbers = knnData.loc[ids[0],:]\n",
    "\n",
    "comparison = pd.DataFrame()\n",
    "comparison[\"SUBJECT_CLIMBER\"]=randomClimber\n",
    "comparison[\"AVERAGE_CLIMBER\"]=knnData.mean()\n",
    "comparison[\"KNN_CLOSEST_AVG\"]=closestClimbers.mean()\n",
    "\n",
    "print(\"After finding the\",str(int(len(knnData.index)/3)),\"nearest neighbors we see this behavior in the data distribution\")\n",
    "display(comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the new group is conformed of climbers with a profile that is closer in similarity to the climber we care about. So now, learning the effect of particular actions on perforance makes more sense, since climbers with very similar bodies and experience intuitively would benefit from similar actions. So if a climber with a similar profile had certain benefit from an action, it would suggest that you probably should too.\n",
    "\n",
    "So lets get back to a predictive modeling using only these subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "Score with 19 features: 0.051416\n",
      "Score with 20 features: 0.105613\n",
      "Score with 15 features: 0.286635\n",
      "Score with 12 features: 0.289198\n",
      "0.075\n",
      "0.1\n",
      "0.15\n"
     ]
    }
   ],
   "source": [
    "neighbors = ids[0][1:]\n",
    "dataG = testBest.copy().drop(climberID,axis=0)\n",
    "modelG = RandomForestRegressor(n_estimators=100)\n",
    "tests = [.05, .075, .1, .15]\n",
    "\n",
    "modelG,featsG,featspG,x_trG,x_tsG,y_trG,y_tsG = trainModel(modelG,dataG,neighbors,tests,\"S_AVG\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so now we have a model trained specifically for the climber of interest. In this case it probably has similar or lower performance than the previous model we trained using all the climbers. This is mainly because we are trying to have it learn complex relationships between dozens of variables using only 50 examples. Even if this data grouping is of better quality than using the entire dataset, the number of registries is still the major limitation at hand. If more data were available, the models' performances would improve dramatically.\n",
    "\n",
    "## Optimization\n",
    "\n",
    "So what can we do with this model? How can we use it to guide improvement?\n",
    "Well, there are various ways. Since we now know the impact of each variable on the target variable, we can try to tweek the variables to optimize the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\tPred\tReal\tError\n",
      "0\t3.9175\t3.5\t-0.4175\n"
     ]
    }
   ],
   "source": [
    "#predictsG = modelG.predict(x_tsG[featsG])\n",
    "#compareG = y_tsG.copy().reset_index(drop=True)\n",
    "\n",
    "predictsG = modelG.predict([testBest.copy().drop(\"S_AVG\",axis=1).loc[climberID,featsG]])\n",
    "compareG = testBest.copy().loc[climberID,'S_AVG']\n",
    "\n",
    "print(\"ID\\tPred\\tReal\\tError\")\n",
    "for i,p in enumerate(predictsG):\n",
    "    print(str(i)+\"\\t\"+str(p)+\"\\t\"+str(compareG)+\"\\t\"+str(compareG-p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, our climber10 has a real climbing average grade of 3.5 (between 5.10b/6a+ and 5.10c/6b) and our algoritm predicts it rather acurrately (it predicts 3.9 which is still between 5.10b/6a+ and 5.10c/6b) using only the variables show below (except \"S_AVG\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NORM</th>\n",
       "      <th>VIEW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>START_AGE</th>\n",
       "      <td>0.232558</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEQTY</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_CLIMB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHOEFIT</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATTEMPTS</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_SELF</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTALTRAIN</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIMBDAYS</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOCUS_EXPLO</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPORT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VACATIONS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YRS_CLIMBING</th>\n",
       "      <td>0.081967</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_AVG</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NORM  VIEW\n",
       "START_AGE     0.232558  20.0\n",
       "ROUTEQTY      0.100000   3.0\n",
       "TRAIN_CLIMB   1.000000   1.0\n",
       "SHOEFIT       0.666667   2.0\n",
       "ATTEMPTS      0.250000   2.0\n",
       "TRAIN_SELF    0.000000   0.0\n",
       "TOTALTRAIN    0.375000   4.5\n",
       "CLIMBDAYS     0.500000   3.0\n",
       "FOCUS_EXPLO   0.000000   0.0\n",
       "SPORT         0.000000   0.0\n",
       "VACATIONS     0.000000   0.0\n",
       "YRS_CLIMBING  0.081967   3.0\n",
       "S_AVG         3.500000   3.5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetClimber = testBest.copy().loc[climberID,featsG]\n",
    "targetClimber[\"S_AVG\"]=testBest.copy().loc[climberID,\"S_AVG\"]\n",
    "targetClimberView = fullData.copy().loc[climberID,featsG]\n",
    "targetClimberView[\"S_AVG\"] = fullData.copy().loc[climberID,\"S_AVG\"]\n",
    "viewClimber = pd.DataFrame()\n",
    "viewClimber[\"NORM\"]=targetClimber\n",
    "viewClimber[\"VIEW\"]=targetClimberView\n",
    "viewClimber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This by itself is already valuable since it allows for a correct assessing of what a climber's performance should/could be based on their profile. However, its also gives us the possibility of exploring what the performance would be if one of those variables were to change.\n",
    "\n",
    "Just stating some characteristics out of the lot, right now our climber...\n",
    "-  Climbs 3 days per week\n",
    "-  Climbs 3 routes per climbing day\n",
    "-  Has been climbing for 3 years\n",
    "-  Trains by simply climbing more instead of creating a training plan by himself/herself\n",
    "-  Attempts hard routes twice a day\n",
    "\n",
    "Based on that lets explore what his/her performance would be with small changes, using the model...\n",
    "-  A: Climb 5 days a week instead of 3\n",
    "-  B: CLimb 6 routes a day instead of 3\n",
    "-  C: Climb for 6 more months\n",
    "-  D: Switch to following a personal training plan instead of just climbing\n",
    "-  E: Attempts hard routes 3 times a day\n",
    "-  F: Combine A, B and E (increase amount of climbing and attempts)\n",
    "-  G: Combine C, D (start a personal training plan and follow it for 6 months) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Now:\t3.5\n",
      "Pred Now\t3.9175\n",
      "Test A\t\t3.6075\tImprove:\t0.10749999999999993\n",
      "Test B\t\t4.8775\tImprove:\t1.3775000000000004\n",
      "Test C\t\t3.9175\tImprove:\t0.4175\n",
      "Test D\t\t4.34\tImprove:\t0.8399999999999999\n",
      "Test E\t\t3.8775\tImprove:\t0.37749999999999995\n",
      "Test F\t\t4.505\tImprove:\t1.005\n",
      "Test G\t\t4.34\tImprove:\t0.8399999999999999\n"
     ]
    }
   ],
   "source": [
    "#predictsG = modelG.predict(x_tsG[featsG])\n",
    "#compareG = y_tsG.copy().reset_index(drop=True)\n",
    "\n",
    "print(\"Real Now:\\t\"+str(compareG))\n",
    "print(\"Pred Now\\t\"+str(predictsG[0]))\n",
    "\n",
    "tester = targetClimber.copy()\n",
    "tester[\"CLIMBDAYS\"] = .875 #Corresponds to 5 days after normalization\n",
    "predictsTest = modelG.predict([tester.drop(\"S_AVG\")])\n",
    "print(\"Test A\\t\\t\"+str(predictsTest[0])+\"\\tImprove:\\t\"+(str(predictsTest[0]-compareG)))\n",
    "\n",
    "tester = targetClimber.copy()\n",
    "tester[\"ROUTEQTY\"] = .2 #Corresponds to 6 routes after normalization\n",
    "predictsTest = modelG.predict([tester.drop(\"S_AVG\")])\n",
    "print(\"Test B\\t\\t\"+str(predictsTest[0])+\"\\tImprove:\\t\"+(str(predictsTest[0]-compareG)))\n",
    "\n",
    "tester = targetClimber.copy()\n",
    "tester[\"YRS_CLIMBING\"] = .09836 #Corresponds to 3.5 years after normalization\n",
    "predictsTest = modelG.predict([tester.drop(\"S_AVG\")])\n",
    "print(\"Test C\\t\\t\"+str(predictsTest[0])+\"\\tImprove:\\t\"+(str(predictsTest[0]-compareG)))\n",
    "\n",
    "tester = targetClimber.copy()\n",
    "tester[\"TRAIN_CLIMB\"] = 0 \n",
    "tester[\"TRAIN_SELF\"] = 1 \n",
    "predictsTest = modelG.predict([tester.drop(\"S_AVG\")])\n",
    "print(\"Test D\\t\\t\"+str(predictsTest[0])+\"\\tImprove:\\t\"+(str(predictsTest[0]-compareG)))\n",
    "\n",
    "tester = targetClimber.copy()\n",
    "tester[\"ATTEMPTS\"] = .5 #Corresponds to 3 attempts after normalization\n",
    "predictsTest = modelG.predict([tester.drop(\"S_AVG\")])\n",
    "print(\"Test E\\t\\t\"+str(predictsTest[0])+\"\\tImprove:\\t\"+(str(predictsTest[0]-compareG)))\n",
    "\n",
    "tester = targetClimber.copy()\n",
    "tester[\"CLIMBDAYS\"] = .875 #Corresponds to 5 days after normalization\n",
    "tester[\"ROUTEQTY\"] = .2 #Corresponds to 6 routes after normalization\n",
    "tester[\"ATTEMPTS\"] = .5 #Corresponds to 3 attempts after normalization\n",
    "predictsTest = modelG.predict([tester.drop(\"S_AVG\")])\n",
    "print(\"Test F\\t\\t\"+str(predictsTest[0])+\"\\tImprove:\\t\"+(str(predictsTest[0]-compareG)))\n",
    "\n",
    "tester = targetClimber.copy()\n",
    "tester[\"YRS_CLIMBING\"] = .09836 #Corresponds to 3.5 years after normalization\n",
    "tester[\"TRAIN_CLIMB\"] = 0 \n",
    "tester[\"TRAIN_SELF\"] = 1 \n",
    "predictsTest = modelG.predict([tester.drop(\"S_AVG\")])\n",
    "print(\"Test G\\t\\t\"+str(predictsTest[0])+\"\\tImprove:\\t\"+(str(predictsTest[0]-compareG)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with this examples we can see what the expected outcome of each possible strategy would be, based on historic factual data of what has worked for other climbers. This could for example guide the climber or coach in which is the most efficient path towards improvement, as one could not simply do everything at the same time, change should usually be gradual.\n",
    "\n",
    "In this example, it seems like if climbing 6 routes instead of 3 routes whenever the climber goes to the crag is what would bring the most improvement, almost all the way to 5.10d/6b+ and it is something well within the climber's control.\n",
    "\n",
    "\n",
    "## Reverse engineering\n",
    "\n",
    "In this example, the different proposed strategies were completely arbitrary, but since we already have the information of the other climbers similar to our climber number 10, we can use that information to suggest a potential approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>START_AGE</th>\n",
       "      <th>ROUTEQTY</th>\n",
       "      <th>TRAIN_CLIMB</th>\n",
       "      <th>SHOEFIT</th>\n",
       "      <th>ATTEMPTS</th>\n",
       "      <th>TRAIN_SELF</th>\n",
       "      <th>TOTALTRAIN</th>\n",
       "      <th>CLIMBDAYS</th>\n",
       "      <th>FOCUS_EXPLO</th>\n",
       "      <th>SPORT</th>\n",
       "      <th>VACATIONS</th>\n",
       "      <th>YRS_CLIMBING</th>\n",
       "      <th>S_AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>7.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.418605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>8.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.220930</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.523256</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     START_AGE  ROUTEQTY  TRAIN_CLIMB   SHOEFIT  ATTEMPTS  TRAIN_SELF  \\\n",
       "23    0.302326  0.233333          0.0  0.333333      0.50         0.0   \n",
       "135   0.116279  0.333333          0.0  0.666667      0.50         0.0   \n",
       "80    0.302326  0.133333          0.0  0.666667      0.00         0.0   \n",
       "13    0.279070  0.166667          0.0  0.333333      0.00         0.0   \n",
       "2     0.302326  0.133333          0.0  1.000000      0.50         0.0   \n",
       "71    0.232558  0.166667          0.0  1.000000      0.25         0.0   \n",
       "115   0.279070  0.166667          0.0  0.666667      0.50         1.0   \n",
       "129   0.325581  0.166667          0.0  0.666667      0.50         0.0   \n",
       "85    0.302326  0.200000          0.0  0.333333      0.50         1.0   \n",
       "88    0.232558  0.100000          0.0  0.333333      0.25         0.0   \n",
       "114   0.209302  0.100000          0.0  0.333333      1.00         0.0   \n",
       "101   0.325581  0.333333          0.0  1.000000      0.25         0.0   \n",
       "52    0.302326  0.200000          0.0  0.666667      0.25         1.0   \n",
       "103   0.337209  0.133333          0.0  0.333333      0.25         0.0   \n",
       "67    0.302326  0.333333          1.0  0.333333      0.50         0.0   \n",
       "70    0.197674  0.166667          1.0  0.333333      0.25         0.0   \n",
       "107   0.279070  0.200000          0.0  0.666667      0.25         0.0   \n",
       "5     0.279070  0.133333          1.0  0.666667      1.00         0.0   \n",
       "140   0.023256  0.233333          1.0  0.333333      0.00         0.0   \n",
       "20    0.290698  0.133333          0.0  0.666667      0.00         1.0   \n",
       "112   0.232558  0.200000          0.0  0.666667      0.50         0.0   \n",
       "144   0.255814  0.133333          0.0  0.666667      0.25         0.0   \n",
       "58    0.325581  0.200000          0.0  0.666667      0.00         0.0   \n",
       "79    0.279070  0.166667          1.0  0.333333      0.50         0.0   \n",
       "95    0.209302  0.133333          0.0  0.666667      0.25         1.0   \n",
       "106   0.255814  0.100000          0.0  0.333333      0.50         1.0   \n",
       "4     0.430233  0.066667          0.0  0.666667      0.50         1.0   \n",
       "29    0.209302  0.200000          1.0  0.666667      0.50         0.0   \n",
       "1     0.279070  0.166667          0.0  0.666667      1.00         1.0   \n",
       "138   0.186047  0.333333          1.0  0.333333      1.00         0.0   \n",
       "26    0.302326  0.200000          0.0  0.000000      1.00         1.0   \n",
       "148   0.186047  0.133333          1.0  1.000000      0.50         0.0   \n",
       "119   0.093023  0.333333          0.0  0.000000      0.25         0.0   \n",
       "81    0.395349  0.266667          0.0  0.666667      0.50         1.0   \n",
       "55    0.186047  0.666667          1.0  0.666667      0.25         0.0   \n",
       "154   0.418605  1.000000          0.0  0.000000      1.00         0.0   \n",
       "151   0.209302  0.200000          0.0  0.666667      0.00         0.0   \n",
       "152   0.220930  0.133333          1.0  0.666667      0.00         0.0   \n",
       "102   0.139535  0.100000          0.0  0.666667      1.00         0.0   \n",
       "142   0.116279  0.233333          0.0  0.666667      0.50         0.0   \n",
       "153   0.418605  0.133333          0.0  0.666667      0.25         0.0   \n",
       "54    0.023256  0.400000          1.0  0.666667      0.00         0.0   \n",
       "139   0.523256  0.200000          0.0  0.666667      1.00         0.0   \n",
       "108   0.232558  0.166667          0.0  0.333333      0.50         0.0   \n",
       "123   0.302326  0.266667          0.0  0.333333      0.50         1.0   \n",
       "45    0.255814  0.133333          0.0  0.333333      0.50         0.0   \n",
       "39    0.209302  0.200000          1.0  0.666667      0.00         0.0   \n",
       "25    0.255814  0.100000          0.0  0.666667      0.25         0.0   \n",
       "59    0.186047  0.166667          0.0  0.666667      1.00         0.0   \n",
       "118   0.162791  0.266667          0.0  0.333333      0.50         0.0   \n",
       "\n",
       "     TOTALTRAIN  CLIMBDAYS  FOCUS_EXPLO  SPORT  VACATIONS  YRS_CLIMBING  S_AVG  \n",
       "23     0.000000   0.166667          0.0    1.0   0.666667      0.049180   5.00  \n",
       "135    0.250000   0.500000          0.0    1.0   0.666667      0.147541   3.50  \n",
       "80     0.500000   0.666667          1.0    1.0   0.333333      0.016393   4.50  \n",
       "13     0.125000   0.333333          1.0    1.0   0.333333      0.049180   1.75  \n",
       "2      0.208333   0.333333          0.0    0.0   0.333333      0.147541   4.00  \n",
       "71     0.416667   0.500000          0.0    0.0   0.666667      0.049180   5.00  \n",
       "115    0.333333   0.333333          1.0    0.0   0.000000      0.016393   5.00  \n",
       "129    0.000000   0.500000          0.0    0.0   0.333333      0.049180   1.25  \n",
       "85     0.416667   0.666667          0.0    0.0   0.666667      0.049180   3.75  \n",
       "88     0.375000   0.666667          0.0    0.0   0.333333      0.049180   3.50  \n",
       "114    0.416667   0.666667          0.0    1.0   0.333333      0.049180   0.00  \n",
       "101    0.000000   0.333333          0.0    1.0   0.333333      0.016393   5.50  \n",
       "52     0.041667   0.500000          0.0    1.0   0.666667      0.081967   6.50  \n",
       "103    0.000000   0.833333          0.0    0.0   0.333333      0.000000   1.25  \n",
       "67     0.000000   0.166667          0.0    0.0   0.666667      0.114754   1.00  \n",
       "70     0.416667   0.500000          0.0    1.0   0.333333      0.032787   2.75  \n",
       "107    0.208333   0.500000          1.0    1.0   0.666667      0.016393   6.25  \n",
       "5      0.625000   0.666667          1.0    0.0   0.333333      0.049180   0.50  \n",
       "140    0.000000   0.333333          0.0    0.0   1.000000      0.213115   5.50  \n",
       "20     0.375000   0.666667          0.0    1.0   0.333333      0.032787   7.00  \n",
       "112    0.125000   0.166667          0.0    0.0   0.000000      0.081967   4.75  \n",
       "144    0.000000   0.333333          1.0    0.0   0.000000      0.081967   1.25  \n",
       "58     0.083333   0.500000          0.0    0.0   0.333333      0.049180   2.75  \n",
       "79     0.625000   0.500000          0.0    1.0   0.666667      0.081967   0.00  \n",
       "95     0.041667   0.500000          0.0    1.0   0.666667      0.114754   5.25  \n",
       "106    0.000000   0.166667          0.0    0.0   0.666667      0.049180   0.00  \n",
       "4      0.250000   0.500000          1.0    0.0   0.333333      0.032787   4.00  \n",
       "29     0.416667   0.500000          0.0    1.0   0.333333      0.245902   6.00  \n",
       "1      0.125000   0.666667          0.0    1.0   0.666667      0.245902   7.00  \n",
       "138    0.875000   0.166667          0.0    0.0   0.000000      0.049180   1.50  \n",
       "26     0.625000   0.500000          0.0    1.0   0.666667      0.081967   6.00  \n",
       "148    0.000000   0.666667          0.0    0.0   0.333333      0.049180   8.50  \n",
       "119    0.000000   0.333333          0.0    1.0   0.333333      0.114754   6.00  \n",
       "81     0.125000   0.500000          0.0    1.0   0.333333      0.049180   7.75  \n",
       "55     0.000000   0.333333          0.0    1.0   0.000000      0.016393   0.00  \n",
       "154    0.000000   0.333333          0.0    0.0   0.333333      0.147541   3.75  \n",
       "151    0.125000   0.500000          0.0    1.0   0.333333      0.016393   8.25  \n",
       "152    0.000000   0.333333          0.0    0.0   0.000000      0.032787   2.50  \n",
       "102    0.000000   0.333333          1.0    0.0   0.333333      0.016393   0.00  \n",
       "142    0.000000   0.666667          1.0    0.0   0.333333      0.114754   0.00  \n",
       "153    0.125000   0.666667          1.0    0.0   0.000000      0.016393   0.00  \n",
       "54     0.208333   0.166667          0.0    1.0   0.333333      0.311475   0.00  \n",
       "139    0.041667   0.500000          0.0    0.0   0.666667      0.065574   4.50  \n",
       "108    0.041667   0.333333          1.0    0.0   0.666667      0.147541   0.00  \n",
       "123    0.625000   0.666667          0.0    1.0   1.000000      0.049180   6.25  \n",
       "45     0.125000   0.500000          0.0    0.0   0.666667      0.081967   5.75  \n",
       "39     0.333333   0.333333          0.0    0.0   0.333333      0.081967   7.50  \n",
       "25     0.125000   0.500000          0.0    0.0   0.666667      0.311475   4.50  \n",
       "59     0.166667   0.666667          1.0    0.0   0.000000      0.114754   0.00  \n",
       "118    0.000000   0.333333          0.0    1.0   0.333333      0.081967   5.00  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betterClosestClimbers = testBest.copy().loc[closestClimbers.index[1:],featsG]\n",
    "betterClosestClimbers[\"S_AVG\"]=testBest.copy().loc[closestClimbers.index[1:],\"S_AVG\"]\n",
    "betterClosestClimbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list of closest climbers, we could focus simply on those that have a higher performance than climber number 10, in order to see what they are doing and imitate them. So we simply filter those and compute their mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CURRENT</th>\n",
       "      <th>IMPROVE</th>\n",
       "      <th>MAXGAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>START_AGE</th>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.272010</td>\n",
       "      <td>0.523256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUTEQTY</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_CLIMB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHOEFIT</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATTEMPTS</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.419643</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_SELF</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTALTRAIN</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.199405</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIMBDAYS</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOCUS_EXPLO</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPORT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VACATIONS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YRS_CLIMBING</th>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.090749</td>\n",
       "      <td>0.311475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_AVG</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>5.669643</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CURRENT   IMPROVE   MAXGAIN\n",
       "START_AGE     0.232558  0.272010  0.523256\n",
       "ROUTEQTY      0.100000  0.221429  1.000000\n",
       "TRAIN_CLIMB   1.000000  0.142857  1.000000\n",
       "SHOEFIT       0.666667  0.571429  1.000000\n",
       "ATTEMPTS      0.250000  0.419643  1.000000\n",
       "TRAIN_SELF    0.000000  0.357143  1.000000\n",
       "TOTALTRAIN    0.375000  0.199405  0.625000\n",
       "CLIMBDAYS     0.500000  0.464286  0.666667\n",
       "FOCUS_EXPLO   0.000000  0.142857  1.000000\n",
       "SPORT         0.000000  0.535714  1.000000\n",
       "VACATIONS     0.000000  0.488095  1.000000\n",
       "YRS_CLIMBING  0.081967  0.090749  0.311475\n",
       "S_AVG         3.500000  5.669643  8.500000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betterClosestClimbers = betterClosestClimbers[betterClosestClimbers[\"S_AVG\"]>targetClimber[\"S_AVG\"]]\n",
    "improveClimb = betterClosestClimbers.mean()\n",
    "hardImprove = betterClosestClimbers.max()\n",
    "viewImprove = pd.DataFrame()\n",
    "viewImprove[\"CURRENT\"]=targetClimber\n",
    "viewImprove[\"IMPROVE\"]=improveClimb\n",
    "viewImprove[\"MAXGAIN\"]=hardImprove\n",
    "viewImprove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, by seeing what the \"better\" climbers with her same profile do, we could come out with individual strategies and try them out just like we did before. But with this we can see the \"sweetspot\" value for each variable and the expected increase assuming the climber had those change of habits.\n",
    "\n",
    "The last thing we just displayed is indirectly some kind of reverse engineering, basically seeing the output and then figuring out how to replicate it. That is one way of doing it based on what other climbers have done, but we could also use computing power to try to mathematically figure out which the best approach would be.\n",
    "\n",
    "Lets try that out to see what the optimal number of routes per day would be for a climber at that current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By climbing 0 climbs a day, climber would climb 3.9125\n",
      "By climbing 3 climbs a day, climber would climb 3.9175\n",
      "By climbing 4 climbs a day, climber would climb 4.02\n",
      "By climbing 6 climbs a day, climber would climb 4.8775\n",
      "By climbing 8 climbs a day, climber would climb 4.92\n"
     ]
    }
   ],
   "source": [
    "maxScore = 0\n",
    "maxClibs = 0\n",
    "for i in range(32):   \n",
    "    tester = targetClimber.copy()\n",
    "    tester[\"ROUTEQTY\"] = i/31\n",
    "    predictsTest = modelG.predict([tester.drop(\"S_AVG\")])\n",
    "    if predictsTest[0] > maxScore:\n",
    "        maxScore = predictsTest[0]\n",
    "        maxClimbs = i\n",
    "        print(\"By climbing\",maxClimbs,\"climbs a day, climber would climb\",maxScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example after forecasting what the grade would be by climbing 1-31 routes a day, the algorithm found that the optimal would be reached by climbing 8 routes a day assuming nothing else changes.\n",
    "\n",
    "In this case we are only looking at a single variable to optimize, in reality you could try to optimize all variables at the same time because their effects are interconnected, but that becomes more complex or unfeasible to try in a \"brufe force\" (what we just did of trying 0 to 31), because there are too many potential combinations to try them. There are many other algorithms for this such as genetic algorithms, greedy algorithms, simulated annealing, etc. but we will not explore them at this time as this was meant mainly as an introductory exercise.\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "In general, this covers pretty much all the steps of a basic/generic data science workflow. Evey step showcased in these notebooks can be made much more complex in order to go into as much detail as desired, but you can work on that by yourself once you are involved in other projects. Data science is much more about creativity and curiosity than it is of hardcore programming. As you saw in these exercises, most of the interesting insights were found because there was a hunch and we simply explored it with rather simple code to see if we could find anything interesting in there. You don't need to be a programming expert to get into data scientist, I actually do not consider myself a very good programmer, I have pretty basic skills and simply use that knowledge + intuition as a tool to play with data, and ask for help either from google or other colleagues whenever I have an idea I want to implement yet lack the technical prowess to do so.\n",
    "\n",
    "Right now some of the processes showcased here are extremely inefficient and would actually not work with larger datasets due to the amount of time or memory they would require, but they are very easy to understand for someone who is just getting into data science. In order to tackle those other scenarios that I mention one must use either a form of parallel computing such as scala/pyspark, or more efficient (yet usually complex) algorithms.\n",
    "\n",
    "Numpy, pandas, scikit_learn, google and stackoverflow are your best friends as a data scientist. Whenever you don't know how to use a tool, or you get errors you don't understand simply googling would either outright answer you guide you towards a good course of action.\n",
    "\n",
    "I hope this was useful, understandable, interesting and easy to follow. And I hope it motivates you to get more into data science if you were already curious about it but didn't know how to start. There are many resourses online for you to get up to speed if you wish to pursue this path.\n",
    "\n",
    "### Note\n",
    "\n",
    "Data science is very dependent on the amount and quality of data. This was performed using only 156 responses (extremely little database) of a survey created by myself, someone with data science knowledge but without any proper knowledge about climbing or sports science, nor the tools to get more detailed quantitative information (rather bad quality of data). With either more responses, or with the help of an actual sports professional to create a more appropiate survey to gather actually useful information, the performance of these kinds of analysis will greatly improve, the results would be more evident and the findings become much more useful.\n",
    "\n",
    "This notebook is a static shot of the code from the last time I ran it, if you download the code and run it in your own computer, the results may change and the \"hardcoded examples\" might stop making any sense because several of the processes are stochastic. This means that they have an intrinsic randomness in their inner workins that causes them to yield different outputs every time you run them, but usually quite similar. This is both good and bad, a good thing is that you can run these processes many times, storing the best result (as we did in the \"trainModel\" methods of this function) to get very good performances, but the bad thing is that they might not be directly replicable if the random seed was not stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
